{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wayne Nixalo - 4 Jun 2017\n",
    "\n",
    "Codealong of Practical Deep Learning I Lesson 4 [statefarm JNB](https://github.com/fastai/courses/blob/master/deeplearning1/nbs/statefarm.ipynb). My comments are in italics.\n",
    "\n",
    "**6 Jun 2017 NOTE: notebook incomplete. Unable to generate convolutional-model features on test data: \"`MemoryError:`\"**\n",
    "\n",
    "## Enter State Farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wnixalo/miniconda3/envs/FAI/lib/python2.7/site-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 870M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, os.path.join('utils'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "path = \"data/statefarm/\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size=32\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19463 images belonging to 10 classes.\n",
      "Found 2961 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path + 'train', batch_size=batch_size)\n",
    "val_batches = get_batches(path + 'valid', batch_size=batch_size*2, shuffle=False)\n",
    "# test_batches = get_batches(path + 'test', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19463 images belonging to 10 classes.\n",
      "Found 2961 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, trn_filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than using batches, we could just import all the data into an array to save some processing time. (In mose examples, I'm using the batches, however - just because that's how I happened to start out.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trn = get_data(path + 'train')\n",
    "# val = get_data(path + 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_array(path + 'results/val.dat', val)\n",
    "# save_array(path + 'results/trn.dat', trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# val = load_array(path + 'results/val.dat')\n",
    "# trn = load_array(path + 'results/trn.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run sample experiments on full dataset\n",
    "\n",
    "We should find that everything that worked on the sample (see statefarm-sample.ipynb), works on the full dataset too. Only better! Because now we have more data. So let's see how they go - the models in this section are exact copies of the sample notebook models.\n",
    "\n",
    "### Single Conv Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "                BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "                Convolution2D(32, 3, 3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Convolution2D(64, 3, 3, activation='relu'),\n",
    "                BatchNormalization(axis=1),\n",
    "                MaxPooling2D((3,3)),\n",
    "                Flatten(),\n",
    "                Dense(200, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dense(10, activation='softmax')\n",
    "            ])\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches,\n",
    "                        nb_val_samples=val_batches.nb_sample)\n",
    "    \n",
    "    model.optimizer.lr = 1e-3\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches,\n",
    "                        nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19463/19463 [==============================] - 246s - loss: 0.2081 - acc: 0.9451 - val_loss: 1.6457 - val_acc: 0.4799\n",
      "Epoch 2/2\n",
      "19463/19463 [==============================] - 230s - loss: 0.0190 - acc: 0.9968 - val_loss: 2.0091 - val_acc: 0.3600\n",
      "Epoch 1/4\n",
      "19463/19463 [==============================] - 234s - loss: 0.0065 - acc: 0.9994 - val_loss: 1.8342 - val_acc: 0.4401\n",
      "Epoch 2/4\n",
      "19463/19463 [==============================] - 231s - loss: 0.0033 - acc: 0.9998 - val_loss: 1.8580 - val_acc: 0.4076\n",
      "Epoch 3/4\n",
      "19463/19463 [==============================] - 231s - loss: 0.0056 - acc: 0.9992 - val_loss: 1.1711 - val_acc: 0.6494\n",
      "Epoch 4/4\n",
      "19463/19463 [==============================] - 230s - loss: 0.0096 - acc: 0.9987 - val_loss: 2.0138 - val_acc: 0.4076\n"
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, with no regularization or augmentation, we're getting some reasonable results from our simple convolutional model. So with augmentation, we hopefully will see some very good results.\n",
    "\n",
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19463 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05,\n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path + 'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19463/19463 [==============================] - 240s - loss: 1.2663 - acc: 0.5893 - val_loss: 1.1617 - val_acc: 0.6278\n",
      "Epoch 2/2\n",
      "19463/19463 [==============================] - 236s - loss: 0.6408 - acc: 0.7995 - val_loss: 0.9994 - val_acc: 0.6964\n",
      "Epoch 1/4\n",
      "19463/19463 [==============================] - 238s - loss: 0.4542 - acc: 0.8631 - val_loss: 0.8759 - val_acc: 0.7221\n",
      "Epoch 2/4\n",
      "19463/19463 [==============================] - 235s - loss: 0.3503 - acc: 0.9010 - val_loss: 0.8460 - val_acc: 0.7291\n",
      "Epoch 3/4\n",
      "19463/19463 [==============================] - 235s - loss: 0.2827 - acc: 0.9194 - val_loss: 0.9318 - val_acc: 0.7717\n",
      "Epoch 4/4\n",
      "19463/19463 [==============================] - 235s - loss: 0.2340 - acc: 0.9347 - val_loss: 0.7082 - val_acc: 0.7943\n"
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "19463/19463 [==============================] - 238s - loss: 0.2069 - acc: 0.9403 - val_loss: 0.6503 - val_acc: 0.8122\n",
      "Epoch 2/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.1960 - acc: 0.9449 - val_loss: 0.7898 - val_acc: 0.7683\n",
      "Epoch 3/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.1721 - acc: 0.9506 - val_loss: 0.6337 - val_acc: 0.8220\n",
      "Epoch 4/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.1537 - acc: 0.9560 - val_loss: 0.7949 - val_acc: 0.8051\n",
      "Epoch 5/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.1443 - acc: 0.9582 - val_loss: 0.7589 - val_acc: 0.7882\n",
      "Epoch 6/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.1336 - acc: 0.9637 - val_loss: 0.7472 - val_acc: 0.7825\n",
      "Epoch 7/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.1236 - acc: 0.9654 - val_loss: 0.8541 - val_acc: 0.7717\n",
      "Epoch 8/15\n",
      "19463/19463 [==============================] - 236s - loss: 0.1118 - acc: 0.9687 - val_loss: 0.6983 - val_acc: 0.8197\n",
      "Epoch 9/15\n",
      "19463/19463 [==============================] - 234s - loss: 0.1133 - acc: 0.9689 - val_loss: 0.6898 - val_acc: 0.8126\n",
      "Epoch 10/15\n",
      "19463/19463 [==============================] - 236s - loss: 0.0975 - acc: 0.9733 - val_loss: 0.5965 - val_acc: 0.8183\n",
      "Epoch 11/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.0930 - acc: 0.9739 - val_loss: 0.7155 - val_acc: 0.8153\n",
      "Epoch 12/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.0961 - acc: 0.9722 - val_loss: 0.7055 - val_acc: 0.8028\n",
      "Epoch 13/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.0858 - acc: 0.9756 - val_loss: 0.6565 - val_acc: 0.8200\n",
      "Epoch 14/15\n",
      "19463/19463 [==============================] - 235s - loss: 0.0769 - acc: 0.9785 - val_loss: 0.5436 - val_acc: 0.8457\n",
      "Epoch 15/15\n",
      "19463/19463 [==============================] - 236s - loss: 0.0749 - acc: 0.9788 - val_loss: 0.6557 - val_acc: 0.8230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec7a019410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=15, validation_data=val_batches,\n",
    "                    nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm shocked by *how* good these results are! We're regularly seeing 75-80% accuracy on the validation set, which puts us into the top third or better of the competition. With such a simple model and no dropout or semi-supervised learning, this really speaks to the power of this approach to data augmentation. *Noted. I'm seeing the same numbers*\n",
    "\n",
    "### Four Conv/Pooling pairs + Dropout\n",
    "\n",
    "Unfortunately, the results are still very unstable - the validation accuracy jumps from epoch to epoch. Perhaps a deeper model with some dropout would help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05,\n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path + 'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3, 224, 224)),\n",
    "            Convolution2D(32, 3, 3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D(),\n",
    "            Convolution2D(64, 3, 3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D(),\n",
    "            Convolution2D(128, 3, 3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D(),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.5),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.5),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19463/19463 [==============================] - 295s - loss: 3.0645 - acc: 0.1751 - val_loss: 1.6314 - val_acc: 0.4877\n",
      "Epoch 2/2\n",
      "19463/19463 [==============================] - 295s - loss: 2.3852 - acc: 0.2982 - val_loss: 1.3944 - val_acc: 0.5326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec90efced0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches,\n",
    "                    nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19463/19463 [==============================] - 295s - loss: 2.0652 - acc: 0.3742 - val_loss: 1.2693 - val_acc: 0.6153\n",
      "Epoch 2/10\n",
      "19463/19463 [==============================] - 295s - loss: 1.8344 - acc: 0.4340 - val_loss: 1.2215 - val_acc: 0.6217\n",
      "Epoch 3/10\n",
      "19463/19463 [==============================] - 295s - loss: 1.6298 - acc: 0.4791 - val_loss: 1.1868 - val_acc: 0.6535\n",
      "Epoch 4/10\n",
      "19463/19463 [==============================] - 295s - loss: 1.4825 - acc: 0.5243 - val_loss: 1.1558 - val_acc: 0.6677\n",
      "Epoch 5/10\n",
      "19463/19463 [==============================] - 295s - loss: 1.3684 - acc: 0.5582 - val_loss: 1.1495 - val_acc: 0.6846\n",
      "Epoch 6/10\n",
      "19463/19463 [==============================] - 295s - loss: 1.2752 - acc: 0.5852 - val_loss: 1.1122 - val_acc: 0.6684\n",
      "Epoch 7/10\n",
      "19463/19463 [==============================] - 295s - loss: 1.2023 - acc: 0.6105 - val_loss: 1.0681 - val_acc: 0.6836\n",
      "Epoch 8/10\n",
      "19463/19463 [==============================] - 295s - loss: 1.1268 - acc: 0.6298 - val_loss: 1.1334 - val_acc: 0.6802\n",
      "Epoch 9/10\n",
      "19463/19463 [==============================] - 294s - loss: 1.0686 - acc: 0.6486 - val_loss: 1.0859 - val_acc: 0.6842\n",
      "Epoch 10/10\n",
      "19463/19463 [==============================] - 295s - loss: 1.0056 - acc: 0.6700 - val_loss: 0.9440 - val_acc: 0.7264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec86035d50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches,\n",
    "                    nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19463/19463 [==============================] - 295s - loss: 0.9563 - acc: 0.6856 - val_loss: 1.0102 - val_acc: 0.7119\n",
      "Epoch 2/10\n",
      "19463/19463 [==============================] - 295s - loss: 0.9028 - acc: 0.7030 - val_loss: 0.9853 - val_acc: 0.7126\n",
      "Epoch 3/10\n",
      "19463/19463 [==============================] - 295s - loss: 0.8503 - acc: 0.7177 - val_loss: 1.0061 - val_acc: 0.7221\n",
      "Epoch 4/10\n",
      "19463/19463 [==============================] - 295s - loss: 0.8053 - acc: 0.7386 - val_loss: 0.9059 - val_acc: 0.7393\n",
      "Epoch 5/10\n",
      "19463/19463 [==============================] - 295s - loss: 0.7798 - acc: 0.7440 - val_loss: 0.8938 - val_acc: 0.7622\n",
      "Epoch 6/10\n",
      "19463/19463 [==============================] - 295s - loss: 0.7333 - acc: 0.7591 - val_loss: 0.9187 - val_acc: 0.7518\n",
      "Epoch 7/10\n",
      "19463/19463 [==============================] - 295s - loss: 0.6912 - acc: 0.7713 - val_loss: 0.8440 - val_acc: 0.7653\n",
      "Epoch 8/10\n",
      "19463/19463 [==============================] - 295s - loss: 0.6783 - acc: 0.7787 - val_loss: 0.8569 - val_acc: 0.7724\n",
      "Epoch 9/10\n",
      "19463/19463 [==============================] - 294s - loss: 0.6495 - acc: 0.7853 - val_loss: 0.8414 - val_acc: 0.7859\n",
      "Epoch 10/10\n",
      "19463/19463 [==============================] - 294s - loss: 0.6258 - acc: 0.7978 - val_loss: 0.8342 - val_acc: 0.7818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec86035e50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches,\n",
    "                    nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.mkdir(path + 'models')\n",
    "model.save_weights(path + 'models/conv8_prelim.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking quite a bit better - the accuracy is similar, but the stability is higher. There's still some way to go however...\n",
    "\n",
    "### Imagenet Conv Features\n",
    "\n",
    "Since we have so little data, and it is similar to ImageNet images (full-color photos), using pre-trained VGG weights is likely to be helpful - in fact it seems likely that we won't need to fine-tune the convolutional layer weights much, if at all. So we can pre-compute the output of the last convolutional layer, as we did in lesson 3 when we experimented with dropout. (However this means that we can't use full data augmentation, since we can't pre-compute something that changes every image.)\n",
    "\n",
    "*NOTE: there is a work-around to this, discussed in lecture: add augmented-versions of the data to the dataset first.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "last_conv_idx = [i for i, l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19463 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# ยก batches shuffle must be set to False when pre-computing features !\n",
    "batches = get_batches(path + 'train', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19463 images belonging to 10 classes.\n",
      "Found 2961 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels,\n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_feat = conv_model.predict_generator(batches, batches.nb_sample)\n",
    "conv_val_feat = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "# conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path + 'results/conv_feat.dat', conv_feat)\n",
    "save_array(path + 'results/conv_val_feat.dat', conv_val_feat)\n",
    "# save_array(path + 'results/conv_test_feat.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2961, 512, 14, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feat = load_array(path + 'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path + 'results/conv_val_feat.dat')\n",
    "# conv_test_feat = load_array(path + 'results/conv_test_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Working on getting conv_test_feat. For some reason getting a nameless \"```MemoryError:```\" every time I run ```conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)```*\n",
    "\n",
    "**Update**: this doesn't throw an error on the Mac using CPU, however, unable on Linux machine to generate test convolutional features. Throwing \"```MemoryError```\" Will see if able to generate predictions on test data through full model.\n",
    "\n",
    "Thought: loading convolutional training and validation features raises memory load from ~2.3 GB to ~10.5 GB.. That's on ~20k imgs. Test data is 80k.. Could the MemoryError be from overloading RAM? But then why is that working just fine on the Mac? Is it an issue with the version of Theano? It's 0.9.0 on both machines...\n",
    "\n",
    "Maybe I should find a way to save generated convolutional test features straight to disk as they're created in batches.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(path + 'test', batch_size=1, shuffle=False, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-023d498bb144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/results/conv_test_feat.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wnixalo/miniconda3/envs/FAI/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                                             \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                                             \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                                             pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wnixalo/miniconda3/envs/FAI/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                         \u001b[0mall_outs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_array(path + '/results/conv_test_feat.dat', conv_model.predict_generator(test_batches, test_batches.nb_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path + 'results/conv_test_feat.dat', conv_test_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm Dense layers on pretrained Conv layers\n",
    "\n",
    "Since we've pre-computed the output of the last convolutional layer, we need to create a network that takes that as input, and predicts our 10 classes. Let's try using a simplified version of VGG's dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/1\n",
      "19463/19463 [==============================] - 5s - loss: 1.5614 - acc: 0.5749 - val_loss: 0.6704 - val_acc: 0.7497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f899e2094d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/2\n",
      "19463/19463 [==============================] - 5s - loss: 0.2692 - acc: 0.9172 - val_loss: 0.5943 - val_acc: 0.7980\n",
      "Epoch 2/2\n",
      "19463/19463 [==============================] - 5s - loss: 0.1412 - acc: 0.9605 - val_loss: 0.6282 - val_acc: 0.7663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bc1c734d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=2,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path + 'models/conv8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bn_model.load_weights(path + 'models/conv8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: \n",
    "\n",
    "*I'm going to leave off the following sections on concatenating DataAugmented versions w/ training data features; and Pseudolabeling, for time. For the massive memory-overhead of concatenating data augmented files/features -- use bcolz to save them and work on it in batches. Sure I'll get experience with that soon.I may train the model w/ dropout below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/4\n",
      "19463/19463 [==============================] - 5s - loss: 0.1100 - acc: 0.9687 - val_loss: 0.6599 - val_acc: 0.7818\n",
      "Epoch 2/4\n",
      "19463/19463 [==============================] - 5s - loss: 0.0746 - acc: 0.9787 - val_loss: 0.6599 - val_acc: 0.7849\n",
      "Epoch 3/4\n",
      "19463/19463 [==============================] - 5s - loss: 0.0638 - acc: 0.9811 - val_loss: 0.8356 - val_acc: 0.7329\n",
      "Epoch 4/4\n",
      "19463/19463 [==============================] - 5s - loss: 0.0600 - acc: 0.9812 - val_loss: 0.9786 - val_acc: 0.7244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f899df730d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.optimizer.lr=0.001\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/4\n",
      "19463/19463 [==============================] - 5s - loss: 0.0606 - acc: 0.9818 - val_loss: 0.9510 - val_acc: 0.7072\n",
      "Epoch 2/4\n",
      "19463/19463 [==============================] - 5s - loss: 0.0499 - acc: 0.9841 - val_loss: 0.7346 - val_acc: 0.7923\n",
      "Epoch 3/4\n",
      "19463/19463 [==============================] - 5s - loss: 0.0481 - acc: 0.9853 - val_loss: 1.3455 - val_acc: 0.6454\n",
      "Epoch 4/4\n",
      "19463/19463 [==============================] - 5s - loss: 0.0494 - acc: 0.9848 - val_loss: 0.7110 - val_acc: 0.7859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bc1bfff10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.optimizer.lr=0.0001\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/8\n",
      "19463/19463 [==============================] - 5s - loss: 0.0387 - acc: 0.9888 - val_loss: 1.3321 - val_acc: 0.6707\n",
      "Epoch 2/8\n",
      "19463/19463 [==============================] - 5s - loss: 0.0355 - acc: 0.9892 - val_loss: 1.1233 - val_acc: 0.6981\n",
      "Epoch 3/8\n",
      "19463/19463 [==============================] - 5s - loss: 0.0328 - acc: 0.9905 - val_loss: 0.7673 - val_acc: 0.7923\n",
      "Epoch 4/8\n",
      "19463/19463 [==============================] - 5s - loss: 0.0343 - acc: 0.9888 - val_loss: 0.9397 - val_acc: 0.7862\n",
      "Epoch 5/8\n",
      "19463/19463 [==============================] - 5s - loss: 0.0367 - acc: 0.9889 - val_loss: 1.2474 - val_acc: 0.7322\n",
      "Epoch 6/8\n",
      "19463/19463 [==============================] - 5s - loss: 0.0291 - acc: 0.9909 - val_loss: 0.8400 - val_acc: 0.7869\n",
      "Epoch 7/8\n",
      "19463/19463 [==============================] - 5s - loss: 0.0235 - acc: 0.9921 - val_loss: 1.1227 - val_acc: 0.7177\n",
      "Epoch 8/8\n",
      "19463/19463 [==============================] - 5s - loss: 0.0273 - acc: 0.9912 - val_loss: 1.0805 - val_acc: 0.7423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f899e241690>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.optimizer.lr=0.00001\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=8,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good! Let's try pre-computing 5 epochs worth of augmented data, so we can experiment with combining dropout and augmentation on the pre-trained model.\n",
    "\n",
    "### Pre-computed DataAugmentation + Dropout\n",
    "\n",
    "We'll use our usual data augmentation parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05,\n",
    "                shear_range=0.1, channel_shif_range=20, width_shift_range=0.1)\n",
    "da_batches = get_batches(path + 'train', gen_t, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use those to create a dataset of convolutional features 5x bigger than the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = conv_model.predict_generator(da_batches, da_batches.nb_smaple*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path + 'results/da_conv_feat.dat', da_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = load_array('results/da_conv_feat.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's include the real trianing data as well in its non-augmented form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = np.concatenate([da_conv_feat, conv_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've now got a dataset 6x bigger than before, we'll need tocopy our labels 6 times too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_trn_labels = np.concatenate([trn_labels]*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on some experiments the previous model works well, with bigger dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_da_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape = conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_da_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model as usual, with pre-computed augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=1,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good - let's save those weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path + 'models/da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/1\n",
      "19463/19463 [==============================] - 7s - loss: 2.7437 - acc: 0.2704 - val_loss: 1.1370 - val_acc: 0.7589\n",
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/4\n",
      "19463/19463 [==============================] - 7s - loss: 1.0967 - acc: 0.6119 - val_loss: 0.7872 - val_acc: 0.7889\n",
      "Epoch 2/4\n",
      "19463/19463 [==============================] - 7s - loss: 0.6871 - acc: 0.7640 - val_loss: 0.6816 - val_acc: 0.7501\n",
      "Epoch 3/4\n",
      "19463/19463 [==============================] - 7s - loss: 0.5364 - acc: 0.8208 - val_loss: 0.5816 - val_acc: 0.7852\n",
      "Epoch 4/4\n",
      "19463/19463 [==============================] - 7s - loss: 0.4298 - acc: 0.8581 - val_loss: 0.6536 - val_acc: 0.7687\n",
      "Train on 19463 samples, validate on 2961 samples\n",
      "Epoch 1/4\n",
      "19463/19463 [==============================] - 7s - loss: 0.3780 - acc: 0.8780 - val_loss: 0.6361 - val_acc: 0.7801\n",
      "Epoch 2/4\n",
      "19463/19463 [==============================] - 7s - loss: 0.3459 - acc: 0.8899 - val_loss: 0.7410 - val_acc: 0.7433\n",
      "Epoch 3/4\n",
      "19463/19463 [==============================] - 7s - loss: 0.3107 - acc: 0.9000 - val_loss: 0.6891 - val_acc: 0.7612\n",
      "Epoch 4/4\n",
      "19463/19463 [==============================] - 7s - loss: 0.2818 - acc: 0.9099 - val_loss: 0.7168 - val_acc: 0.7589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8995af09d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1,\n",
    "             validation_data=(conv_val_feat, val_labels))\n",
    "bn_model.optimizer.lr=0.01\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data=(conv_val_feat, val_labels))\n",
    "bn_model.optimizer.lr=1e-4\n",
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path + 'models/conv8_bn_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-Labeling\n",
    "\n",
    "We're going to try using a combination of [psudeo labeling](http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf) and [knowledge distillation](https://arxiv.org/abs/1503.02531) to allow us to use unlabeled data (ie: do semi-supervised learning). For our initial experiment we'll use the validation set as the unlabled data, so that we can see that it is working without using the test set. At a layer date we'll try using the test set.\n",
    "\n",
    "To do this, we can simply calculate the predictions of our model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pseudo = bn_model.predict(conv_val_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...concatenate them with our training labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0fdb3db5e74f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcomb_pseudo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pseudo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcomb_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_val_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "comb_pseudo = np.concatenate([trn_labels, val_pseudo])\n",
    "comb_feat = np.concatenate([trn_labels, conv_val_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_pseudo = np.concatenate([da_trn_labels, val_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_feat = np.concatenate([da_conv_feat, conv_val_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and fine-tune our model using that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(path _ + 'models/da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=1,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4,\n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a distinct improvement - even although the validation set isn't very big. This looks encouraging for when we try this on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path + 'models/bn-ps8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit\n",
    "\n",
    "We'll find a good clipping amount using the validation set, prior to submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1 - mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_preds = bn_model.predict(conv_val_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.7353486965074808)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.metrics.categorical_crossentropy(val_labels, do_clip(val_preds, 0.93)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-86f55d1296aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconb_test_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_model' is not defined"
     ]
    }
   ],
   "source": [
    "conb_test_feat = conv_model.predict_generator(test_batches, test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(path + 'results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bn_model.predict(conv_test_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds, 0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path + 'results/subm.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'img', [a[4:] for a in test_filenames]) # <-- why a[4:]?\n",
    "# submission.insert(0, 'img', [f[8:] for f in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets 0.534 on the leaderboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
